{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "basetable = pd.read_csv('basetable_ex2_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>gender_F</th>\n",
       "      <th>income_high</th>\n",
       "      <th>income_low</th>\n",
       "      <th>country_USA</th>\n",
       "      <th>country_India</th>\n",
       "      <th>country_UK</th>\n",
       "      <th>age</th>\n",
       "      <th>time_since_last_gift</th>\n",
       "      <th>time_since_first_gift</th>\n",
       "      <th>max_gift</th>\n",
       "      <th>min_gift</th>\n",
       "      <th>mean_gift</th>\n",
       "      <th>number_gift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>530</td>\n",
       "      <td>2265</td>\n",
       "      <td>166.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>116.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>715</td>\n",
       "      <td>715</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>150</td>\n",
       "      <td>1806</td>\n",
       "      <td>125.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>96.00</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>725</td>\n",
       "      <td>2274</td>\n",
       "      <td>117.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>104.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>805</td>\n",
       "      <td>805</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  gender_F  income_high  income_low  country_USA  country_India  \\\n",
       "0       0         1            0           1            0              1   \n",
       "1       0         1            0           0            0              1   \n",
       "2       0         1            0           0            0              1   \n",
       "3       0         1            0           1            1              0   \n",
       "4       0         1            1           0            1              0   \n",
       "\n",
       "   country_UK  age  time_since_last_gift  time_since_first_gift  max_gift  \\\n",
       "0           0   65                   530                   2265     166.0   \n",
       "1           0   71                   715                    715      90.0   \n",
       "2           0   28                   150                   1806     125.0   \n",
       "3           0   52                   725                   2274     117.0   \n",
       "4           0   82                   805                    805      80.0   \n",
       "\n",
       "   min_gift  mean_gift  number_gift  \n",
       "0      87.0     116.00            7  \n",
       "1      90.0      90.00            1  \n",
       "2      74.0      96.00            9  \n",
       "3      97.0     104.25            4  \n",
       "4      80.0      80.00            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basetable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shubham\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = basetable[[\"age\", \"gender_F\", \"time_since_last_gift\"]]\n",
    "y = basetable[[\"target\"]]\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe new_data from current_data that has only the relevant predictors \n",
    "new_data = X[[\"age\", \"gender_F\", \"time_since_last_gift\"]]\n",
    "\n",
    "# Make a prediction for each observation in new_data and assign it to predictions\n",
    "predictions = logreg.predict(new_data)\n",
    "print(predictions[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating AUC\n",
    "- The AUC value assesses how well a model can order observations from low probability to be target to high probability to be target. In Python, the roc_auc_score function can be used to calculate the AUC of the model. It takes the true values of the target and the predictions as arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = logreg.predict_proba(X)\n",
    "predictions_target = predictions[:,-1]\n",
    "\n",
    "# Calculate the AUC value\n",
    "auc = roc_auc_score(y, predictions_target)\n",
    "print(round(auc,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using different set of variables to calculate AUC score\n",
    "- Adding more variables and therefore more complexity to our logistic regression model does not automatically result in more accurate models. Here we can verify whether adding 3 variables to a model leads to a more accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68\n",
      "0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shubham\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shubham\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Shubham\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shubham\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Create appropriate dataframes\n",
    "variables_1 = ['mean_gift', 'income_low']\n",
    "variables_2 = ['mean_gift', 'income_low', 'gender_F', 'country_India', 'age']\n",
    "\n",
    "X_1 = basetable[variables_1]\n",
    "X_2 = basetable[variables_2]\n",
    "y = basetable[[\"target\"]]\n",
    "\n",
    "# Create the logistic regression model\n",
    "logreg = linear_model.LogisticRegression()\n",
    "\n",
    "# Make predictions using the first set of variables and assign the AUC to auc_1\n",
    "logreg.fit(X_1, y)\n",
    "predictions_1 = logreg.predict_proba(X_1)[:,1]\n",
    "auc_1 = roc_auc_score(y, predictions_1)\n",
    "\n",
    "# Make predictions using the second set of variables and assign the AUC to auc_2\n",
    "logreg.fit(X_2, y)\n",
    "predictions_2 = logreg.predict_proba(X_2)[:,1]\n",
    "auc_2 = roc_auc_score(y, predictions_2)\n",
    "\n",
    "# Print auc_1 and auc_2\n",
    "print(round(auc_1,2))\n",
    "print(round(auc_2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that the model with 5 variables has the same AUC as the model using only 2 variables. Adding more variables doesn't always increase the AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward stepwise variable selection : Intutive way of variable selection\n",
    "\n",
    "### Selecting the next best variable\n",
    "- The forward stepwise variable selection method starts with an empty variable set and proceeds in steps, where in each step the next best variable is added.\n",
    "- The **`auc`** function calculates for a given variable set variables the AUC of the model that uses this variable set as predictors. \n",
    "- The **`next_best`** function calculates which variable should be added in the next step to the variable list. \n",
    "- **Task** :  experiment with these functions to better understand their purpose. We will calculate the AUC of a given variable set, calculate which variable should be added next, and verify that this indeed results in an optimal AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate AUC\n",
    "def auc(variables, target, basetable):\n",
    "    \"\"\"calculates AUC\"\"\"\n",
    "    X = basetable[variables]\n",
    "    y = basetable[target]\n",
    "    \n",
    "    logreg = linear_model.LogisticRegression()\n",
    "    logreg.fit(X,y)\n",
    "    \n",
    "    predictions = logreg.predict_proba(X)[:,1]\n",
    "    auc = roc_auc_score(y, predictions)\n",
    "    return auc\n",
    "\n",
    "def next_best(current_variable, candidate_variables, target, basetable):\n",
    "    \"\"\"function looks throughout candidate variables and keeps track of which  variable is best and the auc associated with the best variable\"\"\"\n",
    "    best_auc = -1\n",
    "    best_variable = None\n",
    "    \n",
    "    # for each variable in the candidate variable set calculate the AUC\n",
    "    # current_variable : variables which are already in the model\n",
    "    # extend it with the variable with which we need to evaluate\n",
    "    for v in candidate_variables:\n",
    "        auc_v = auc(candidate_variables + [v], target, basetable)\n",
    "        \n",
    "    # if this AUC is better then the best AUC, change the best AUC and best variable\n",
    "    if auc_v >= best_auc:\n",
    "        best_auc = auc_v\n",
    "        best_variable = v\n",
    "    return best_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7125\n",
      "gender_F\n",
      "0.7148\n",
      "0.713\n"
     ]
    }
   ],
   "source": [
    "# Calculate the AUC of a model that uses \"max_gift\", \"mean_gift\" and \"min_gift\" as predictors\n",
    "auc_current = auc([\"max_gift\", \"mean_gift\", \"min_gift\"], [\"target\"], basetable)\n",
    "print(round(auc_current,4))\n",
    "\n",
    "# Calculate which variable among \"age\" and \"gender_F\" should be added to the variables \"max_gift\", \"mean_gift\" and \"min_gift\"\n",
    "next_variable = next_best([\"max_gift\", \"mean_gift\", \"min_gift\"], [\"age\", \"gender_F\"], [\"target\"], basetable)\n",
    "print(next_variable)\n",
    "\n",
    "# Calculate the AUC of a model that uses \"max_gift\", \"mean_gift\", \"min_gift\" and \"age\" as predictors\n",
    "auc_current_age = auc([\"max_gift\", \"mean_gift\", \"min_gift\", \"age\"], [\"target\"], basetable)\n",
    "print(round(auc_current_age,4))\n",
    "\n",
    "# Calculate the AUC of a model that uses \"max_gift\", \"mean_gift\", \"min_gift\" and \"gender_F\" as predictors\n",
    "auc_current_gender_F = auc([\"max_gift\", \"mean_gift\", \"min_gift\", \"gender_F\"], [\"target\"], basetable)\n",
    "print(round(auc_current_gender_F,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model that has `gender_F` as next variable has a better AUC than the model that has `age` as next variable. Therefore, `gender_F` is selected as the next best variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the order of variables\n",
    "- The forward stepwise variable selection procedure starts with an empty set of variables, and adds predictors one by one. In each step, the predictor that has the highest AUC in combination with the current variables is selected. \n",
    "- **Task** : implement the forward stepwise variable selection procedure. To this end, we can use the next_best function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender_F', 'income_high', 'income_low', 'country_USA', 'country_India', 'country_UK', 'age', 'time_since_last_gift', 'time_since_first_gift', 'max_gift', 'min_gift', 'mean_gift', 'number_gift']\n"
     ]
    }
   ],
   "source": [
    "# Find the candidate variables\n",
    "candidate_variables = list(basetable.columns.values)\n",
    "candidate_variables.remove(\"target\")\n",
    "print(candidate_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable added in step 1 is time_since_last_gift.\n",
      "Variable added in step 2 is age.\n",
      "Variable added in step 3 is country_UK.\n",
      "Variable added in step 4 is country_India.\n",
      "Variable added in step 5 is country_USA.\n",
      "['time_since_last_gift', 'age', 'country_UK', 'country_India', 'country_USA']\n"
     ]
    }
   ],
   "source": [
    "# Initialize the current variables\n",
    "current_variables = []\n",
    "\n",
    "# The forward stepwise variable selection procedure\n",
    "number_iterations = 5\n",
    "for i in range(0, number_iterations):\n",
    "    next_variable = next_best(current_variables, candidate_variables, [\"target\"], basetable)\n",
    "    current_variables = current_variables + [next_variable]\n",
    "    candidate_variables.remove(next_variable)\n",
    "    print(\"Variable added in step \" + str(i+1)  + \" is \" + next_variable + \".\")\n",
    "print(current_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlated variables\n",
    "- The first 10 variables that are added to the model are the following: \n",
    "`['max_gift', 'number_gift', 'time_since_last_gift', 'mean_gift', 'income_high', 'age', 'country_USA', 'gender_F', 'income_low', 'country_UK']`\n",
    "- `min_gift` is not added. Does this mean that it is a bad variable? We can test the performance of the variable by using it in a model as a single variable and calculating the AUC. How does the AUC of `min_gift` compare to the AUC of `income_high`? To this end, we can use the function auc()\n",
    "- It can happen that a **good variable is not added because it is highly correlated with a variable that is already in the model**. We can test this calculating the correlation between these variables\n",
    "\n",
    "```python\n",
    "import numpy\n",
    "numpy.corrcoef(basetable[\"variable_1\"],basetable[\"variable_2\"])[0,1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Calculate the AUC of the model using the variable `min_gift` only.\n",
    "- Calculate the AUC of the model using the variable `income_high` only.\n",
    "- Calculate the correlation between the variable `min_gift` and `mean_gift`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57\n",
      "0.52\n",
      "0.76\n"
     ]
    }
   ],
   "source": [
    "# Calculate the AUC of the model using min_gift only\n",
    "auc_min_gift = auc([\"min_gift\"], [\"target\"], basetable)\n",
    "print(round(auc_min_gift,2))\n",
    "\n",
    "# Calculate the AUC of the model using income_high only\n",
    "auc_income_high = auc([\"income_high\"], [\"target\"], basetable)\n",
    "print(round(auc_income_high,2))\n",
    "\n",
    "# Calculate the correlation between min_gift and mean_gift\n",
    "correlation = np.corrcoef(basetable[\"min_gift\"], basetable[\"mean_gift\"])[0,1]\n",
    "print(round(correlation,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  `min_gift` has more predictive power than `income_high`, but that it is highly correlated with `mean_gift` and therefore not included in the selected variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitioning\n",
    "- In order to properly evaluate a model, one can partition the data in a train and test set. The train set contains the data the model is built on, and the test data is used to evaluate the model. This division is done randomly, but when the target incidence is low, it could be necessary to stratify, that is, to make sure that the train and test data contain an equal percentage of targets. \n",
    "- **Task** : partition the data with stratification and verify that the train and test data have equal target incidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the partitioning module\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n",
      "0.05\n"
     ]
    }
   ],
   "source": [
    "# Create dataframes with variables and target\n",
    "X = basetable.drop(\"target\", 1)\n",
    "y = basetable[\"target\"]\n",
    "\n",
    "# Carry out 50-50 partititioning with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, stratify = y)\n",
    "\n",
    "# Create the final train and test basetables\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Check whether train and test have same percentage targets\n",
    "print(round(sum(train['target'])/len(train), 2))\n",
    "print(round(sum(test['target'])/len(test), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The stratify option makes sure the target incidence is the same in both train and test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating a model on test and train\n",
    "- **Task** : apply AUC function, and check whether the train and test AUC are similar.\n",
    "- Calculate the train and test AUC of the model using `\"age\"` and `\"gender_F\"` as predictors using the auc_train_test function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n",
      "0.53\n"
     ]
    }
   ],
   "source": [
    "# Carry out 70-30 partititioning with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify = y)\n",
    "\n",
    "# Create the final train and test basetables\n",
    "train = pd.concat([X_train, y_train], axis=1)\n",
    "test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "auc_train = auc([\"age\", \"gender_F\"], \"target\", train)\n",
    "auc_test = auc([\"age\", \"gender_F\"], \"target\", test)\n",
    "\n",
    "print(round(auc_train,2))\n",
    "print(round(auc_test,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It could happen that the test AUC is slightly lower than the train AUC. This is a perfectly normal phenomenon called over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the AUC curves\n",
    "- **The forward stepwise variable selection procedure provides an order in which variables are optimally added to the predictor set. In order to decide where to cut off the variables, we can make the train and test AUC curves. These curves plot the train and test AUC using the first, first two, first three, ... variables in the model.**\n",
    "- **Task** : plot these AUC curves\n",
    "- variables = ['max_gift',\n",
    " 'time_since_last_gift',\n",
    " 'number_gift',\n",
    " 'mean_gift',\n",
    " 'income_high',\n",
    " 'age',\n",
    " 'gender_F',\n",
    " 'time_since_first_gift',\n",
    " 'income_low',\n",
    " 'country_UK']\n",
    " \n",
    "- `auc_values_train`,  will contain the train AUC values of the model at each iteration\n",
    "- `auc_values_test`, will contain the test AUC values of the model at each iteration\n",
    "- `variables_evaluate`, will contain the variables evaluated at each iteration\n",
    "\n",
    "**************************************************************\n",
    "- Iterate over the variables.\n",
    "- In each iteration, add the next variable in variables to variables_evaluate.\n",
    "- In each iteration, calculate the train and test AUC using the auc method. The dataframes train and test contain the train and test data respectively.\n",
    "- In each iteration, add the calculated values to auc_values_train and auc_values_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Keep track of train and test AUC values\n",
    "auc_values_train = []\n",
    "auc_values_test = []\n",
    "variables_evaluate = []\n",
    "\n",
    "variables = ['max_gift',\n",
    " 'time_since_last_gift',\n",
    " 'number_gift',\n",
    " 'mean_gift',\n",
    " 'income_high',\n",
    " 'age',\n",
    " 'gender_F',\n",
    " 'time_since_first_gift',\n",
    " 'income_low',\n",
    " 'country_UK']\n",
    "\n",
    "# Iterate over the variables in variables\n",
    "for v in variables:\n",
    "  \n",
    "    # Add the variable\n",
    "    variables_evaluate.append(v)\n",
    "    \n",
    "    # Calculate the train and test AUC of this set of variables\n",
    "    auc_train = auc(variables_evaluate, \"target\", train)\n",
    "    auc_test = auc(variables_evaluate, \"target\", test)\n",
    "    \n",
    "    # Append the values to the lists\n",
    "    auc_values_train.append(auc_train)\n",
    "    auc_values_test.append(auc_test)\n",
    "    \n",
    "# Make plot of the AUC values\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.array(range(0,len(auc_values_train)))\n",
    "y_train = np.array(auc_values_train)\n",
    "y_test = np.array(auc_values_test)\n",
    "plt.xticks(x, variables, rotation = 90)\n",
    "plt.plot(x,y_train)\n",
    "plt.plot(x,y_test)\n",
    "plt.ylim((0.6, 0.8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that the test AUC curve starts declining sooner than the train curve. The point at which this happens is a good cut-off."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
